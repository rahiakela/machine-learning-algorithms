{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural-networks-from-scratch.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO7DaHFKJpCefwugXqbpmib",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/machine-learning-algorithms/blob/main/neural-networks-from-scratch/02-coding-neurons/neural_networks_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbnwqiAyQMSy"
      },
      "source": [
        "##A Single Neuron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiZNd6RrQfMs"
      },
      "source": [
        "Let’s say we have a single neuron, and there are three inputs to this neuron. As in most cases, when you initialize parameters in neural networks, our network will have weights initialized randomly, and biases set as zero to start.\n",
        "\n",
        "The input will be either actual training data or the outputs of neurons from the previous layer in the neural network. We’re just going to make up values to start with as input for now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBYRtb8sSQ73"
      },
      "source": [
        "inputs = [1, 2, 3]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbOogcYbWX9R"
      },
      "source": [
        "Each input also needs a weight associated with it. Inputs are the data that we pass into the model\n",
        "to get desired outputs, while the weights are the parameters that we’ll tune later on to get these\n",
        "results. Weights are one of the types of values that change inside the model during the training\n",
        "phase, along with biases that also change during training. The values for weights and biases are\n",
        "what get “trained,” and they are what make a model actually work (or not work).\n",
        "\n",
        "Let’s say the first input, at index 0, which is a 1, has a weight of\n",
        "0.2, the second input has a weight of 0.8, and the third input has a weight of -0.5. \n",
        "\n",
        "Our input and weights lists should now be:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1svllTbZWqaH"
      },
      "source": [
        "inputs = [1, 2, 3]\n",
        "weights = [0.2, 0.8, -0.5]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMMJEvJXW4Tc"
      },
      "source": [
        "Next, we need the bias. At the moment, we’re modeling a single neuron with three inputs. Since\n",
        "we’re modeling a single neuron, we only have one bias, as there’s just one bias value per neuron.\n",
        "\n",
        "The bias is an additional tunable value but is not associated with any input in contrast to the\n",
        "weights. We’ll randomly select a value of 2 as the bias for this example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4XU7xdiW9fF"
      },
      "source": [
        "inputs = [1, 2, 3]\n",
        "weights = [0.2, 0.8, -0.5]\n",
        "bias = 2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtJ2N4R7XGrH"
      },
      "source": [
        "This neuron sums each input multiplied by that input’s weight, then adds the bias. All the neuron\n",
        "does is take the fractions of inputs, where these fractions (weights) are the adjustable parameters,\n",
        "and adds another adjustable parameter — the bias — then outputs the result.\n",
        "\n",
        "<img src='https://github.com/rahiakela/machine-learning-algorithms/blob/main/neural-networks-from-scratch/02-coding-neurons/images/1.png?raw=1' width='800'/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqPn8NcBXAD2",
        "outputId": "82b42b23-ee9e-4998-82ae-87227eb4e0a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "output = (inputs[0] * weights[0] +\n",
        "          inputs[1] * weights[1] +\n",
        "          inputs[2] * weights[2] +\n",
        "          bias)\n",
        "print(output)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJN3A1PvX24l"
      },
      "source": [
        "What might we need to change if we have 4 inputs, rather than the 3 we’ve just shown? \n",
        "\n",
        "Next to\n",
        "the additional input, we need to add an associated weight, which this new input will be multiplied\n",
        "with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URjVpIV9XbSU"
      },
      "source": [
        "inputs = [1.0, 2.0, 3.0, 2.5]\n",
        "weights = [0.2, 0.8, -0.5, 1.0]\n",
        "bias = 2.0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZForwbsYEBa"
      },
      "source": [
        "Which could be depicted visually as:\n",
        "\n",
        "<img src='https://github.com/rahiakela/machine-learning-algorithms/blob/main/neural-networks-from-scratch/02-coding-neurons/images/2.png?raw=1' width='800'/>\n",
        "\n",
        "All together in code, including the new input and weight, to produce output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUf6vFr8YOc3",
        "outputId": "3a6a2c5e-c933-4802-f723-500d7c6dc7af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputs = [1.0, 2.0, 3.0, 2.5]\n",
        "weights = [0.2, 0.8, -0.5, 1.0]\n",
        "bias = 2.0\n",
        "\n",
        "output = (inputs[0] * weights[0] +\n",
        "          inputs[1] * weights[1] +\n",
        "          inputs[2] * weights[2] +\n",
        "          inputs[3] * weights[3] +\n",
        "          bias)\n",
        "print(output)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DcsGuOwYa0z"
      },
      "source": [
        "<img src='https://github.com/rahiakela/machine-learning-algorithms/blob/main/neural-networks-from-scratch/02-coding-neurons/images/3.png?raw=1' width='800'/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyTJiXp5YhmI"
      },
      "source": [
        "##A Layer of Neurons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXHBBu8KYic_"
      },
      "source": [
        "Neural networks typically have layers that consist of more than one neuron. Layers are nothing\n",
        "more than groups of neurons. Each neuron in a layer takes exactly the same input — the input\n",
        "given to the layer (which can be either the training data or the output from the previous layer),\n",
        "but contains its own set of weights and its own bias, producing its own unique output. The layer’s\n",
        "output is a set of each of these outputs — one per each neuron. \n",
        "\n",
        "Let’s say we have a scenario with\n",
        "3 neurons in a layer and 4 inputs:\n",
        "\n",
        "<img src='https://github.com/rahiakela/machine-learning-algorithms/blob/main/neural-networks-from-scratch/02-coding-neurons/images/4.png?raw=1' width='800'/>\n",
        "\n",
        "We’ll keep the initial 4 inputs and set of weights for the first neuron the same as we’ve been using\n",
        "so far. We’ll add 2 additional, made up, sets of weights and 2 additional biases to form 2 new\n",
        "neurons for a total of 3 in the layer. \n",
        "\n",
        "The layer’s output is going to be a list of 3 values, not just a\n",
        "single value like for a single neuron."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teZk6m7RYWmm",
        "outputId": "f3b63ebe-6de0-4a42-c9c2-34b4d8886a7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputs = [1.0, 2.0, 3.0, 2.5]\n",
        "\n",
        "weights1 = [0.2, 0.8, -0.5, 1.0]\n",
        "weights2 = [0.5, -0.91, 0.26, -0.5]\n",
        "weights3 = [-0.26, -0.27, 0.17, 0.87]\n",
        "\n",
        "bias1 = 2.0\n",
        "bias2 = 3.0\n",
        "bias3 = 0.5\n",
        "\n",
        "output = [\n",
        "    # Neuron 1\n",
        "    inputs[0] * weights1[0] +\n",
        "    inputs[1] * weights1[1] +\n",
        "    inputs[2] * weights1[2] +\n",
        "    inputs[3] * weights1[3] + bias1,\n",
        "\n",
        "    # Neuron 2\n",
        "    inputs[0] * weights2[0] +\n",
        "    inputs[1] * weights2[1] +\n",
        "    inputs[2] * weights2[2] +\n",
        "    inputs[3] * weights2[3] + bias2,\n",
        "\n",
        "    # Neuron 3\n",
        "    inputs[0] * weights3[0] +\n",
        "    inputs[1] * weights3[1] +\n",
        "    inputs[2] * weights3[2] +\n",
        "    inputs[3] * weights3[3] + bias3,\n",
        "]\n",
        "\n",
        "print(output)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.8, 1.21, 2.385]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUr7KWc9cLNg"
      },
      "source": [
        "<img src='https://github.com/rahiakela/machine-learning-algorithms/blob/main/neural-networks-from-scratch/02-coding-neurons/images/5.png?raw=1' width='800'/>\n",
        "\n",
        "Each\n",
        "neuron is “connected” to the same inputs. The difference is in the separate weights and bias\n",
        "that each neuron applies to the input. This is called a fully connected neural network — every\n",
        "neuron in the current layer has connections to every neuron from the previous layer.\n",
        "\n",
        "At this point, we have only shown code for a single layer\n",
        "with very few neurons. Imagine coding many more layers and more neurons. This would get\n",
        "very challenging to code using our current methods. \n",
        "\n",
        "Instead, we could use a loop to scale and\n",
        "handle dynamically-sized inputs and layers. We’ve turned the separate weight variables into a\n",
        "list of weights so we can iterate over them, and we changed the code to use loops instead of\n",
        "the hardcoded operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-UeX_xab5YA",
        "outputId": "c6ebc7ba-6593-4985-91a7-70aa30ce1f59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputs = [1.0, 2.0, 3.0, 2.5]\n",
        "\n",
        "weights = [\n",
        "  [0.2, 0.8, -0.5, 1.0],\n",
        "  [0.5, -0.91, 0.26, -0.5],\n",
        "  [-0.26, -0.27, 0.17, 0.87]\n",
        "]\n",
        "\n",
        "biases = [2.0, 3.0, 0.5]\n",
        "\n",
        "# Output of current layer\n",
        "layer_outputs = []\n",
        "# For each neuron\n",
        "for n_weights, n_bias in zip(weights, biases):\n",
        "  # Zeroed output of given neuron\n",
        "  n_output = 0\n",
        "  # For each input and weight to the neuron\n",
        "  for n_input, weight in zip(inputs, n_weights):\n",
        "    # Multiply this input by associated weight and add to the neuron’s output variable\n",
        "    n_output += n_input * weight\n",
        "  # Add bias\n",
        "  n_output += n_bias\n",
        "  # Put neuron’s result to the layer’s output list\n",
        "  layer_outputs.append(n_output)\n",
        "\n",
        "print(layer_outputs)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.8, 1.21, 2.385]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SefajBUwehkG"
      },
      "source": [
        "This does the same thing as before, just in a more dynamic and scalable way.\n",
        "\n",
        "Again, all we’re doing is, for each neuron (the outer loop in the code above, over neuron weights\n",
        "and biases), taking each input value multiplied by the associated weight for that input (the inner\n",
        "loop in the code above, over inputs and weights), adding all of these together, then adding a bias\n",
        "at the end. Finally, sending the neuron’s output to the layer’s output list.\n",
        "\n",
        "That’s it! How do we know we have three neurons? Why do we have three?\n",
        "\n",
        "We can tell we have\n",
        "three neurons because there are 3 sets of weights and 3 biases.\n",
        "\n",
        "When you make a neural network\n",
        "of your own, you also get to decide how many neurons you want for each of the layers. You can\n",
        "combine however many inputs you are given with however many neurons that you desire.\n",
        "\n",
        "**With our above code that uses loops, we could modify our number of inputs or neurons in our\n",
        "layer to be whatever we wanted, and our loop would handle it.**\n",
        "\n",
        "It would be a disservice not to show NumPy here since Python alone doesn’t do matrix/tensor/array math very efficiently.\n",
        "\n",
        "But first, the reason the most popular deep learning library in Python is\n",
        "called **TensorFlow** is that it’s all about doing operations on tensors ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A7EWxpwhAEl"
      },
      "source": [
        "##Tensors, Arrays and Vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jIBjlwIhBMl"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KhCzFW_eOIS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}