{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-part-of-speech-tagging-with-spacy.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOh7CXOLaAco4PYmohjnCxX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/machine-learning-algorithms/blob/main/Essential-NLP/04-information-extraction/1_part_of_speech_tagging_with_spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLlSdPejwIUX"
      },
      "source": [
        "##Part-of-speech tagging with spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az_VbEjXwQ1H"
      },
      "source": [
        "Unlike NLTK that treats different components of language analysis as separate steps, spaCy\n",
        "builds an analysis pipeline from the very beginning and applies this pipeline to text. Under\n",
        "the hood, the pipeline already includes a number of useful NLP tools that are run on input\n",
        "text without you needing to call on them separately. \n",
        "\n",
        "These tools include, among others, a\n",
        "tokenizer and a POS tagger. You simply apply the whole lot of tools with a single line of code\n",
        "calling on the spaCy processing pipeline, and then your program stores the result in a\n",
        "convenient format until you need it. This also ensures that the information is passed between\n",
        "the tools without you taking care of the input-output formats.\n",
        "\n",
        "<img src='images/1.png?raw=1' width='800'/>\n",
        "\n",
        "That means that each of the three tools –\n",
        "tokenizer, stemmer, POS tagger – requires a different type of input and produces a different\n",
        "type of output, so in order to apply them in sequence we need to know how to represent\n",
        "information for each of them. That is what spaCy’s processing pipeline does for you: it runs a\n",
        "sequence of tools and connects their outputs together.\n",
        "\n",
        "You may notice that the processing tools are comprised within a pipeline\n",
        "called nlp. As you will shortly see in the code, calling on nlp pipeline makes the program\n",
        "first invoke all the pre-trained tools and then applies them to the input text. The output of all\n",
        "the steps gets stored in a “container” called Doc – it contains a sequence of tokens extracted\n",
        "from input text and processed with the tools. Here is where spaCy implementation comes\n",
        "close to object-oriented programming: the tokens are represented as Token objects with a\n",
        "specific set of attributes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iw4HFbozDIH"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0b1JWPZzEQY"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import string\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from pathlib import Path"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivB_7GnP81XJ"
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuBTLl031VAJ"
      },
      "source": [
        "##POS tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKg-cGuB1XwK"
      },
      "source": [
        "This is the approach taken by spaCy to represent tokens in text: after tokenization, each\n",
        "token (word) is packed up in an object Token that has a number of attributes.\n",
        "- `token.text` contains the original word itself;\n",
        "- `token.lemma`_ stores the lemma (base form) of the word;\n",
        "- `token.pos_` – its part-of-speech tag;\n",
        "- `token.i` – the index position of the word in text;\n",
        "- `token.lower_` – lowercase form of the word, and so on.\n",
        "\n",
        "The nlp pipeline aims to fill in the information fields like lemma, pos and others with the\n",
        "values specific for each particular token. Since different tools within the pipeline provide\n",
        "different bits of information, the values for the attributes are added on the go.\n",
        "\n",
        "<img src='images/2.png?raw=1' width='800'/>\n",
        "\n",
        "Now, there are a couple of points that we did not get to discuss before: imagine there are a hundred of documents in total and you can quickly skim through them to filter out the most irrelevant ones – those that do not even mention either “meetings” or “management”.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEapD-vr7TtX"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"On Friday board members meet with senior managers to discuss future development of the company.\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9ytuXyj8-xV",
        "outputId": "92034af1-94df-404a-b057-43110f14bf5a"
      },
      "source": [
        "rows = []\n",
        "rows.append([\"Word\", \"Position\", \"Lowercase\", \"Lemma\", \"POS\", \"Alphanumeric\", \"Stopword\"])\n",
        "# Add the attributes of each token in the processed text to the output for printing\n",
        "for token in doc:\n",
        "  rows.append([token.text, str(token.i), token.lower_, token.lemma_, token.pos_, str(token.is_alpha), str(token.is_stop)])\n",
        "\n",
        "columns = zip(*rows)\n",
        "column_widths = [max(len(item) for item in col) for col in columns]\n",
        "# As each column will contain strings of variable lengths, calculate the maximum length of strings in each column to allow enough space in the printout\n",
        "for row in rows:\n",
        "  print(\"\".join(' {:{width}} '.format(row[i], width=column_widths[i]) for i in range(0, len(row))))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Word         Position  Lowercase    Lemma        POS    Alphanumeric  Stopword \n",
            " On           0         on           on           ADP    True          True     \n",
            " Friday       1         friday       Friday       PROPN  True          False    \n",
            " board        2         board        board        NOUN   True          False    \n",
            " members      3         members      member       NOUN   True          False    \n",
            " meet         4         meet         meet         VERB   True          False    \n",
            " with         5         with         with         ADP    True          True     \n",
            " senior       6         senior       senior       ADJ    True          False    \n",
            " managers     7         managers     manager      NOUN   True          False    \n",
            " to           8         to           to           PART   True          True     \n",
            " discuss      9         discuss      discuss      VERB   True          False    \n",
            " future       10        future       future       ADJ    True          False    \n",
            " development  11        development  development  NOUN   True          False    \n",
            " of           12        of           of           ADP    True          True     \n",
            " the          13        the          the          DET    True          True     \n",
            " company      14        company      company      NOUN   True          False    \n",
            " .            15        .            .            PUNCT  False         False    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAImxu6LCoHI"
      },
      "source": [
        "The POS tagging algorithm, similarly, takes into account two types of expectations: an\n",
        "expectation that a certain type of a word (like modal verb) may follow a certain other type of\n",
        "a word (like pronoun), and an expectation that if it is a modal verb such a verb may be\n",
        "“can”. These “expectations” are calculated using the data: for example, to find out how likely\n",
        "it is that a modal verb follows a pronoun, we calculate the proportion of times we see a\n",
        "modal verb following a pronoun in data among all the cases where we saw a pronoun. \n",
        "\n",
        "For\n",
        "instance, if we saw 10 pronouns like “I” and “we” in data before, and 5 times out of those 10\n",
        "these pronouns were followed by a modal verb like “can” or “may” (as in “I can” and “we\n",
        "may”), what would the likelihood, or probability, or seeing a modal verb following a pronoun\n",
        "be?\n",
        "\n",
        "<img src='images/3.png?raw=1' width='800'/>\n",
        "\n",
        "We can calculate it as:\n",
        "- Probability(modal verb follows pronoun) = 5 / 10\n",
        "\n",
        "or in general case:\n",
        "- Probability(modal verb follows pronoun) = \n",
        "- How_often(pronoun is followed by verb) /\n",
        "- How_often(pronoun is followed by any type of word, modal verb or not)\n",
        "\n",
        "Similarly, to estimate how likely (or how probable) it is that the pronoun is “I”, we need to\n",
        "take the number of times we’ve seen a pronoun “I” and divide it by the number of times\n",
        "we’ve seen any pronouns in the data. So, if among those 10 pronouns that we’ve seen in the\n",
        "data before 7 were “I” and 3 were “we”, the probability of seeing a pronoun “I” would be\n",
        "estimated.\n",
        "\n",
        "<img src='images/4.png?raw=1' width='800'/>\n",
        "\n",
        "- Probability(pronoun being “I”) = 7 / 10\n",
        "\n",
        "or in general case:\n",
        "- Probability(pronoun being “I”) =\n",
        "- How_often(we’ve seen a pronoun “I”) /\n",
        "- How_often(we’ve seen any pronoun, “I” or other)\n",
        "\n",
        "In the end, the algorithm goes through the sequence of tags and words one by one, and\n",
        "takes all the probabilities into account. Since the probability of each decision, that is each tag\n",
        "and each word, is a separate step in the process, these individual probabilities are multiplied.\n"
      ]
    }
  ]
}