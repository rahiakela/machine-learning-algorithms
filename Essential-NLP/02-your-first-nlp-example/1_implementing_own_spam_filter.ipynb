{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-implementing-own-spam-filter.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNNUyQoi8880a40MWySG9Ta",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/machine-learning-algorithms/blob/main/Essential-NLP/02-your-first-nlp-example/1_implementing_own_spam_filter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLlSdPejwIUX"
      },
      "source": [
        "##Implementing own spam filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az_VbEjXwQ1H"
      },
      "source": [
        "In this notebook, you use the spam filtering as your practical NLP application as it is an example of a very widely spread family of tasks – text classification. Text classification comprises a number of applications, for example user profiling, sentiment analysis and topic labeling, so this\n",
        "will give you a good start for the rest of the book. \n",
        "\n",
        "First, let’s see what exactly classification addresses.\n",
        "\n",
        "We, humans apply classification in our everyday lives pretty regularly: classifying things simply implies that we try to put them into clearly defined groups, classes or categories. \n",
        "\n",
        "In fact, we tend to classify all sorts of things all the time. Here are some examples:\n",
        "\n",
        "- based on our level of engagement and interest in a movie, we may classify it as interesting or boring;\n",
        "- based on temperature, we classify water as cold or hot;\n",
        "- based on the amount of sunshine, humidity, wind strength and air temperature, we classify the weather as good or bad;\n",
        "- based on the number of wheels, we classify vehicles into unicycles, bicycles, tricycles, quadricycles, cars and so on;\n",
        "- based on the availability of the engine, we may classify two-wheeled vehicles into bicycles and motorcycles.\n",
        "\n",
        "Classification is useful because it makes it easier for us to reason about things and adjust our behavior accordingly.\n",
        "\n",
        "When classifying things, we often go for simple contrasts – good vs. bad, interesting vs. boring, hot vs. cold. When we are dealing with two labels only, this is called binary classification.\n",
        "\n",
        "Classification that implies more than two classes is called multi-class classification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iw4HFbozDIH"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0b1JWPZzEQY"
      },
      "source": [
        "import os\n",
        "import codecs\n",
        "import random\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk import NaiveBayesClassifier, classify\n",
        "from nltk.text import Text"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHRXbiApBXvX",
        "outputId": "6cb17155-3d12-4d3a-ef10-125f3933d2a8"
      },
      "source": [
        "%%shell\n",
        "\n",
        "wget -qq https://github.com/ekochmar/Essential-NLP/raw/master/enron1.zip\n",
        "unzip -qq enron1.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuBTLl031VAJ"
      },
      "source": [
        "##Step 1: Define the data and classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKg-cGuB1XwK"
      },
      "source": [
        "Enron email dataset is a large dataset of emails (the original dataset contains about 0.5M messages), including both ham and spam emails, for about 150 users, mostly senior management of Enron.\n",
        "\n",
        "We are going to use enron1/ folder for training. All folders in Enron\n",
        "dataset contain spam and ham emails in separate subfolders, so you don’t need to worry about pre-defining them. Each email is stored as a text file in these subfolders. \n",
        "\n",
        "Let’s read in the contents of these text files in each subfolder, store the spam emails contents and the ham emails contents as two separate data structures and point our algorithm at each, clearly\n",
        "defining which one is spam and which one is ham."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyB2rC7cAXv0"
      },
      "source": [
        "def read_files(folder):\n",
        "  files = os.listdir(folder)\n",
        "  a_list = []\n",
        "  for a_file in files:\n",
        "    # Skip hidden files, that are sometimes automatically created by the operating systems. They can be easily identified because their names start with “.”\n",
        "    if not a_file.startswith(\".\"):\n",
        "      file = codecs.open(folder + a_file, \"r\", encoding=\"ISO-8859-1\", errors=\"ignore\")\n",
        "      a_list.append(file.read())\n",
        "      file.close()\n",
        "  return a_list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRBJFb2GDOBS"
      },
      "source": [
        "Now you can define two such lists – spam_list and ham_list, letting the machine know what data to use as examples of spam emails and what data represents ham emails."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8u2XdijC_8n",
        "outputId": "eb4b39e3-6253-4cc0-c90b-b4084a91180b"
      },
      "source": [
        "spam_list = read_files(\"enron1/spam/\")\n",
        "ham_list = read_files(\"enron1/ham/\")\n",
        "\n",
        "# Check the lengths of the lists: for spam it should be 1500 and for ham – 3672\n",
        "print(len(spam_list))\n",
        "print(len(ham_list))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1500\n",
            "3672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBSBQjjlD_GZ"
      },
      "source": [
        "Let's check out the contents of the first entry. In both cases, it should coincide with the contents of the first file in each correspondent subfolder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGjDZk7qDw6v",
        "outputId": "1b55ba94-0c0f-4b52-f85b-cfb387d3e046"
      },
      "source": [
        "print(spam_list[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Subject: buy your medicines from us, viagra, xanax and more.\r\n",
            "No doctor visit needed.\r\n",
            "Remove.\r\n",
            "Back you' ll tiny lot wrote you' ve what have say would picked are being\r\n",
            "Now you? Good then postpone to mom. Once. Thing loved lost you' d so it\r\n",
            "I' ve changed weeks. These can' t really that in never into time wants it' s\r\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xuyuJyVD0ve",
        "outputId": "8b078dcb-6cb4-448c-e39e-d7122a820251"
      },
      "source": [
        "print(ham_list[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Subject: shoreline gas, inc. Shoreline buhler central point (meter 098 - 9860)\r\n",
            "Bob, shoreline has requested that hpl change the current nomination at meter 098 - 9860 from 2, 473 mmbtu/d to 4, 150 mmbtu/d effective 5/12/2001; the sitara deal is 453067.\r\n",
            "George x 3159\r\n",
            "- - - - - - - - - - - - - - - - - - - - - - forwarded by george weissman/hou/ect on 05/11/2001 04: 06 pm - - - - - - - - - - - - - - - - - - - - - - - - - - -\r\n",
            "Donna consemiu\r\n",
            "09/29/2000 01: 27 pm\r\n",
            "To: molly l carriere/hou/ect@ ect, clem cernosek/hou/ect@ ect, gary a hanks/hou/ect@ ect, james mckay/hou/ect@ ect, michael w morris/hou/ect@ ect, jack simunek/hou/ect@ ect, chris sonneborn/hou/ect@ ect, david stadnick/hou/ect@ ect, steve van hooser/hou/ect@ ect, esther buckley/hou/ect@ ect, donna consemiu/hou/ect@ ect, nathan l hlavaty/hou/ect@ ect, steve hpl schneider/hou/ect@ ect, nagesh kavi/hou/ect@ ect, melissa graves/hou/ect@ ect, mary m smith/hou/ect@ ect, jackie young/hou/ect@ ect, vance l taylor/hou/ect@ ect, fred boas/hou/ect@ ect, j r fosdick/gco/enron@ enron, vicente sarmiento/gco/enron@ enron, reid hansen/gco/enron@ enron, cheryl jones/gpgfin/enron@ enron, gary anderson/gpgfin/enron@ enron, jackie morgan/hou/ect@ ect, amelia alland/hou/ect@ ect, george weissman/hou/ect@ ect, susan smith/hou/ect@ ect, donald p reinhardt/hou/ect@ ect, pat clynes/corp/enron@ enron, cheryl dudley/hou/ect@ ect, shawna flynn/hou/ect@ ect, audrey o' neil/hou/ect@ ect, michael eiben/hou/ect@ ect, anita luong/hou/ect@ ect, jennifer d pattison/hou/ect@ ect, howard b camp/hou/ect@ ect, robert cotten/hou/ect@ ect, sabrae zajac/hou/ect@ ect, earl tisdale/hou/ect@ ect, cathy l harris/hou/ect@ ect\r\n",
            "Cc:\r\n",
            "Subject: revision: new hpl meter - hollimon central point (meter 098 - 9860)\r\n",
            "Revision: name change\r\n",
            "The name has been changed to: shoreline buhler central point to match the work order.\r\n",
            "Donna consemiu\r\n",
            "09/29/2000 08: 09 am\r\n",
            "To:\r\n",
            "Cc:\r\n",
            "Subject: new hpl meter - hollimon central point (meter 098 - 9860)\r\n",
            "Fyi\r\n",
            "The below houston pipe line meter has been set up in global facilities.\r\n",
            "Meter: 098 - 9860\r\n",
            "Facility number: 515228\r\n",
            "Name: hollimon central point\r\n",
            "Type: producer connection\r\n",
            "System: 550 - victoria - texas city junction mainline\r\n",
            "Rate zone: 23 (tom o' conner)\r\n",
            "Trade zone: 5 (edna)\r\n",
            "Flow direction: receipt\r\n",
            "Drn: 286538\r\n",
            "Lateral:\r\n",
            "Work order #:\r\n",
            "Please call me at ext. 3 - 3446 if you have any questions.\r\n",
            "Donna\r\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSAN2RwlEYHf"
      },
      "source": [
        "Next, you’ll need to preprocess the data (e.g., by splitting text strings into words) and extract the features.\n",
        "\n",
        "Finally, remember that you will need to split the data randomly into the\n",
        "training and test sets. \n",
        "\n",
        "Let’s shuffle the resulting list of emails with their labels, and make\n",
        "sure that the shuffle is reproducible by fixing the way in which the data is shuffled:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RiJyKNlEkja",
        "outputId": "4343b3c8-aff2-4d34-b92d-3b113f81e023"
      },
      "source": [
        "# for each member of the ham_list and spam_list it stores a tuple with the content and associated label\n",
        "all_emails = [(email_content, \"spam\") for email_content in spam_list]\n",
        "all_emails += [(email_content, \"ham\") for email_content in ham_list]\n",
        "\n",
        "# By defining the seed for the random operator you can make sure that all future runs will shuffle the data in the same way\n",
        "random.seed(2020)\n",
        "random.shuffle(all_emails)\n",
        "\n",
        "# it should be equal to 1500 + 3672 = 5172\n",
        "print(f\"Dataset size = {str(len(all_emails))} emails\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset size = 5172 emails\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWi887yuFvSO"
      },
      "source": [
        "##Step 2: Split the text into words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLddWLQCFwDH"
      },
      "source": [
        ""
      ]
    }
  ]
}